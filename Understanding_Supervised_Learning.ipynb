{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Understanding Supervised Learning**\n",
        "\n",
        "Supervised Learning is one of the foundational techniques in ML. It involves training a model using a labeled dataset, where each training example has corresponding inputs and outputs. The objective is for the model to learn the relationship between inputs and outputs, so it can make accurate predictions on unseen data.\n",
        "\n",
        "For example, in image classification, the labeled dataset would consist of images of objects along with their corresponding labels. By training on this data, the model learns to identify the objects in new images."
      ],
      "metadata": {
        "id": "3i7mwwBPFh-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Demo:**\n",
        "\n",
        "Let's create a simple image classifier using Logistic Regression in Google Colab. We'll use the popular library scikit-learn for this task."
      ],
      "metadata": {
        "id": "S4BXTwhuFsu9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvzGnuW5D9C0"
      },
      "outputs": [],
      "source": [
        "#First, we need to install scikit-learn.\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import necessary libraries and modules.\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "V9Cqz0XNF530"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a sample dataset\n",
        "\n",
        "features = np.array([[0.5, 0.7], [0.1, 0.4], [0.3, 0.2], [0.7, 0.9]])\n",
        "\n",
        "labels = np.array(['cat', 'dog', 'cat', 'dog'])"
      ],
      "metadata": {
        "id": "eqed5wOqF_bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)"
      ],
      "metadata": {
        "id": "B1-UkBxdGK4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearSVC()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "DFmrKSr3GPXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions on test data.\n",
        "predictions = model.predict(test_features)"
      ],
      "metadata": {
        "id": "GVFkty8fGYoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model's accuracy.\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "wAyZ6DNvGf6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Understanding Weakly Supervised Learning**\n",
        "\n",
        "Weakly Supervised Learning is designed to handle partially labeled data, where obtaining precise and abundant labels for all training examples is challenging or costly. One popular technique in Weakly Supervised Learning is \"Multiple Instance Learning\" (MIL). It operates on bags of instances, where each bag contains multiple instances, but only the bag itself is labeled. The model learns to identify patterns within the instances to make predictions for the entire bag."
      ],
      "metadata": {
        "id": "d3Hg5FgQGnPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Demo:**\n",
        "\n",
        "Let's build a simple MIL classifier using Support Vector Machine (SVM) in Google Colab."
      ],
      "metadata": {
        "id": "REB3vzODGyiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing required dependencies\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "CCNjlvmrGz8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weakly Supervised Learning - Sample dataset (bags of instances and corresponding bag labels)\n",
        "# Each bag contains 2 instances, but only the bag itself is labeled.\n",
        "bags = np.array([[[1.2, 3.4], [0.5, 2.3]], [[2.1, 4.5], [4.5, 2.1]], [[3.4, 1.2], [1.2, 3.4]]])\n",
        "bag_labels = np.array(['positive', 'negative', 'positive'])"
      ],
      "metadata": {
        "id": "UEdx3BWjG8ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create bag representations\n",
        "bag_representations = np.sum(bags, axis=1)[..., np.newaxis]\n",
        "\n",
        "# Reshape into 2D\n",
        "train_bags = train_bags.reshape(len(train_bags), -1)\n",
        "test_bags = test_bags.reshape(len(test_bags), -1)"
      ],
      "metadata": {
        "id": "jF3CRBSkT6iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the Weakly Supervised model (Support Vector Machine)\n",
        "model = SVC(probability=True)\n",
        "# Train model\n",
        "model.fit(train_bags, train_bag_labels)"
      ],
      "metadata": {
        "id": "qr4CsssxHNPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on test data\n",
        "predictions = model.predict(test_bags)"
      ],
      "metadata": {
        "id": "VuZ9yOIHKU4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model's accuracy.\n",
        "accuracy = accuracy_score(test_bag_labels, predictions)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "RCcwCJuNKbIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Understanding Self-Supervised Learning**\n",
        "\n",
        "Self-Supervised Learning is a semi-supervised approach where the model generates its own labels from the given data. It achieves this by creating a pretext task, which is an auxiliary task related to the primary task of interest. Solving the pretext task helps the model learn representations that can be transferred to the primary task, even with limited labeled data."
      ],
      "metadata": {
        "id": "YesuJJFbKkHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Demo:\n",
        "\n",
        "Let's implement a simple Self-Supervised Learning technique using TensorFlow in Google Colab."
      ],
      "metadata": {
        "id": "7HGN2wrKKreB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First, install TensorFlow.\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "9-Kt3kJSKvA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import necessary libraries and modules.\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Concatenate\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "dH0p94P_K0qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset (images with missing parts and corresponding original images)\n",
        "self_supervised_images_with_missing_parts = np.array([[[1, 2, 3], [0, 0, 0]], [[4, 5, 6], [0, 0, 0]], [[7, 8, 9], [0, 0, 0]]])\n",
        "self_supervised_original_images = np.array([[[1, 2, 3], [4, 5, 6]], [[4, 5, 6], [7, 8, 9]], [[7, 8, 9], [1, 2, 3]]])\n",
        "\n",
        "# Expand dimensions to include the channel dimension (single channel for grayscale)\n",
        "self_supervised_images_with_missing_parts = np.expand_dims(self_supervised_images_with_missing_parts, axis=-1)\n",
        "self_supervised_original_images = np.expand_dims(self_supervised_original_images, axis=-1)"
      ],
      "metadata": {
        "id": "80YZz6PKK8Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Self-Supervised model\n",
        "input_shape = self_supervised_images_with_missing_parts.shape[1:]\n",
        "input_layer = Input(shape=input_shape)\n",
        "conv_layer = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "upsample_layer = UpSampling2D((2, 2))(conv_layer)\n",
        "\n",
        "# Resize the upsampled layer to match the input layer's shape\n",
        "upsample_layer_resized = tf.image.resize(upsample_layer, input_shape[:2])\n",
        "\n",
        "output_layer = Concatenate()([input_layer, upsample_layer_resized])\n",
        "\n",
        "model = Model(input_layer, output_layer)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n"
      ],
      "metadata": {
        "id": "ILO2FU9VLDdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model to fill in missing parts\n",
        "model.fit(self_supervised_images_with_missing_parts, self_supervised_original_images, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "VYCA2bYqLLfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Don't forget to tag @inamdarmihir in your implementations and star the code repository on Github: https://www.github.com/inamdarmihir/simplify-ml/"
      ],
      "metadata": {
        "id": "iHqQJ8OALwsF"
      }
    }
  ]
}